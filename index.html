<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="color-scheme" content="dark light">
    <meta name="description" content="An exploration of leveraging AI for software development, focusing on system design, prompt engineering, and effectiveness analysis.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <title>Software Engineering Journal: Data Structure, Algorithm, System Design</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono&display=swap" rel="stylesheet">
    <script>
        function toggleTheme() {
            document.body.classList.toggle('dark-theme');
            document.documentElement.classList.toggle('dark-theme');
            const theme = document.body.classList.contains('dark-theme') ? 'dark' : 'light';
            localStorage.setItem('theme', theme);
        }

        // Apply saved theme on load
        document.addEventListener('DOMContentLoaded', () => {
            const savedTheme = localStorage.getItem('theme') || 'light';
            if (savedTheme === 'dark') {
                document.body.classList.add('dark-theme');
                document.documentElement.classList.add('dark-theme');
            }
            
            // Mobile menu toggle functionality
            const mobileMenuToggle = document.getElementById('mobile-menu-toggle');
            const navList = document.getElementById('nav-list');
            
            if (mobileMenuToggle && navList) {
                mobileMenuToggle.addEventListener('click', () => {
                    navList.classList.toggle('active');
                });
                
                // Close mobile menu when a link is clicked
                const navLinks = navList.querySelectorAll('a');
                navLinks.forEach(link => {
                    link.addEventListener('click', () => {
                        navList.classList.remove('active');
                    });
                });
            }
        });
    </script>
</head>
<body>
    <nav class="nav">
        <div class="nav-container">
            <div class="nav-logo">DSA Guide</div>
            <button class="mobile-menu-toggle" id="mobile-menu-toggle" aria-label="Toggle navigation menu">‚ò∞</button>            <ul class="nav-list" id="nav-list">
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#essential-notions">Essential Notions</a></li>
                <li><a href="#data-structures">Data Structures</a></li>
                <li><a href="#programming-techniques">Programming Techniques</a></li>
                <li><a href="#system-design">System Design</a></li>
                <li><a href="#methodology">Methodology</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
            </ul>
            <button class="theme-toggle" onclick="toggleTheme()">
                <span class="theme-icon">üåì</span>
            </button>
        </div>
    </nav>

    <main class="container">
        <header class="page-header">
            <h1>Modern Software Engineering Guide</h1>
            <p class="subtitle">Data Structures, Algorithms, and System Design</p>
        </header>        <div class="content-grid">
            <section id="introduction">
                <h2>Introduction</h2>
                <div class="highlight">
                    <p>Welcome to the Modern Software Engineering Guide. This comprehensive resource is designed to help software engineers, developers, and computer science students understand and apply fundamental concepts in data structures, algorithms, and system design.</p>
                    
                    <p>In today's rapidly evolving technology landscape, a strong foundation in these core concepts is essential for building efficient, scalable, and maintainable software systems. Whether you're preparing for technical interviews, working on complex software projects, or simply expanding your knowledge, this guide provides structured insights into the building blocks of modern software engineering.</p>
                    
                    <p>Throughout this guide, we'll explore various data structures, algorithmic patterns, and system design principles with practical examples and visualizations to enhance understanding. Let's embark on this journey to strengthen your software engineering fundamentals.</p>
                </div>
            </section>

            <section id="essential-notions">
                <h2>Essential Notions</h2>

                <h3>Complexity Analysis</h3>
                <div class="highlight">
                    <h4>Big O Notation</h4>
                    <p>A mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Time Complexity</div>
                        <p class="ds-description">Measures the amount of computational time required by an algorithm to run as a function of the input size.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Common Time Complexities:</strong>
                                <ul class="feature-list">
                                    <li><strong>O(1)</strong> - Constant Time: Execution time remains the same regardless of input size</li>
                                    <li><strong>O(log n)</strong> - Logarithmic Time: Execution time grows logarithmically with input size</li>
                                    <li><strong>O(n)</strong> - Linear Time: Execution time grows linearly with input size</li>
                                    <li><strong>O(n log n)</strong> - Linearithmic Time: Common in efficient sorting algorithms</li>
                                    <li><strong>O(n¬≤)</strong> - Quadratic Time: Execution time grows quadratically with input size</li>
                                    <li><strong>O(2‚Åø)</strong> - Exponential Time: Execution time doubles with each addition to the input</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Analysis Guidelines:</strong>
                                <ul class="feature-list">
                                    <li>Focus on worst-case scenario when analyzing algorithms</li>
                                    <li>Drop constants and lower-order terms</li>
                                    <li>Consider the dominant operations in nested loops</li>
                                    <li>Different inputs may need separate variables (e.g., O(n+m))</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Space Complexity</div>
                        <p class="ds-description">Measures the amount of memory space required by an algorithm as a function of the input size.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Considerations:</strong>
                                <ul class="feature-list">
                                    <li>Auxiliary space: Extra space used by the algorithm (excluding input)</li>
                                    <li>Input space: Space used to store the input</li>
                                    <li>Total space: Sum of auxiliary and input space</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Space Optimizations:</strong>
                                <ul class="feature-list">
                                    <li>In-place algorithms: Modify input directly with O(1) extra space</li>
                                    <li>Tail recursion: Optimizing recursive calls to avoid stack growth</li>
                                    <li>Iterative over recursive implementations when possible</li>
                                    <li>Memory pooling and object reuse for repeated operations</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Algorithm Analysis Framework</h3>
                <div class="highlight">
                    <h4>Evaluating Algorithm Efficiency</h4>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Trade-offs in Algorithm Design</div>
                        <p class="ds-description">Understanding the balance between competing factors when designing algorithms:</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Common Trade-offs:</strong>
                                <ul class="feature-list">
                                    <li>Time vs. Space complexity</li>
                                    <li>Preprocessing time vs. Query time</li>
                                    <li>Average-case vs. Worst-case performance</li>
                                    <li>Simplicity vs. Efficiency</li>
                                    <li>Generality vs. Customization</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Decision Factors:</strong>
                                <ul class="feature-list">
                                    <li>Input size and constraints</li>
                                    <li>Access patterns (random vs. sequential)</li>
                                    <li>Hardware limitations</li>
                                    <li>Frequency of operations</li>
                                    <li>Scalability requirements</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Amortized Analysis</div>
                        <p class="ds-description">A method of analyzing algorithms that considers the average performance of operations over a sequence of operations, even when some operations might be occasionally expensive.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Analysis Methods:</strong>
                                <ul class="feature-list">
                                    <li>Aggregate method: Total cost averaged over operations</li>
                                    <li>Accounting method: Assign different costs to different operations</li>
                                    <li>Potential method: Uses a potential function to track data structure state</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Dynamic arrays with resizing operations</li>
                                    <li>Balanced trees with rebalancing operations</li>
                                    <li>Hash tables with rehashing operations</li>
                                    <li>Disjoint-set data structure operations</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Problem-Solving Approaches</h3>
                <div class="highlight">
                    <h4>Methodical Problem-Solving</h4>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Problem Decomposition</div>
                        <p class="ds-description">Breaking complex problems into smaller, manageable sub-problems that can be solved independently.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Techniques:</strong>
                                <ul class="feature-list">
                                    <li>Top-down decomposition</li>
                                    <li>Bottom-up synthesis</li>
                                    <li>Divide and conquer approach</li>
                                    <li>Identifying independent components</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Benefits:</strong>
                                <ul class="feature-list">
                                    <li>Reduces problem complexity</li>
                                    <li>Enables parallel problem-solving</li>
                                    <li>Facilitates reuse of solutions</li>
                                    <li>Improves code organization</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Pattern Recognition</div>
                        <p class="ds-description">Identifying common patterns in problems that can be solved using established techniques or algorithms.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Common Patterns:</strong>
                                <ul class="feature-list">
                                    <li>Sliding window problems</li>
                                    <li>Two-pointer techniques</li>
                                    <li>Graph traversal patterns</li>
                                    <li>Dynamic programming substructures</li>
                                    <li>Divide and conquer approaches</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Pattern Application Process:</strong>
                                <ul class="feature-list">
                                    <li>Recognize problem characteristics</li>
                                    <li>Match to known patterns</li>
                                    <li>Adapt pattern solution to specific problem</li>
                                    <li>Verify correctness with test cases</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="data-structures">
                <h2>Common Data Structures in Modern Development</h2>

                <h3>Linear Data Structures</h3>
                <div class="highlight">
                    <h4>Arrays and Lists</h4>
                    <p>Fundamental sequential storage structures:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Arrays</div>
                        <p class="ds-description">Linear data structure that stores elements in consecutive memory locations, enabling access using indices. Each element can be accessed directly with its index in constant time O(1). Arrays are particularly useful for tasks that involve sorting, searching, and optimization.</p>
                        
                        <!-- Add Search2DMatrix image for matrix section -->
                        <div class="image-container">
                            <img src="Public/Search2DMatrix.png" alt="2D Matrix Search Algorithm Visualization" class="algorithm-image">
                            <p class="image-caption">Search in a 2D Matrix: Elements are sorted row-wise and column-wise</p>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>O(1) time complexity for accessing elements by index</li>
                                    <li>O(n) time complexity for insertion/deletion</li>
                                    <li>Contiguous memory allocation provides locality of reference</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Techniques:</strong>
                                <ul class="feature-list">
                                    <li>Two Pointer Techniques</li>
                                    <li>Sliding Window</li>
                                    <li>Binary Search</li>
                                    <li>Sorting (Merge Sort, Quick Sort, Insertion Sort)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Data Buffer</li>
                                    <li>Matrix operations</li>
                                    <li>Searching algorithms</li>
                                    <li>Caching</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                      <div class="data-structure-card">
                        <div class="ds-title">Dynamic Arrays (ArrayList)</div>
                        <p class="ds-description">Random access, variable-size list that automatically grows when inserting elements when there's no space left for new items.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Amortized O(1) insertion at end</li>
                                    <li>Memory overhead for flexibility</li>
                                    <li>Dynamic resizing capability</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Dynamic collections</li>
                                    <li>Buffer management</li>
                                    <li>When size requirements are unknown</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="section-divider"></div>

                    <h4>Stacks and Queues</h4>
                    <p>LIFO and FIFO data structures:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Stack</div>
                        <p class="ds-description">Linear data structure that operates using the LIFO Principle (Last In First Out), making them suitable for tasks that require elements to be accessed in reverse order. Functions like a stack of plates where the last element added is the first one retrieved.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Operations:</strong>
                                <ul class="feature-list">
                                    <li>Push: Add an element to the top</li>
                                    <li>Pop: Remove the top element</li>
                                    <li>Peek: View the top element without removing</li>
                                    <li>isEmpty: Check if stack is empty</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Function call management (recursion)</li>
                                    <li>Expression evaluation</li>
                                    <li>Backtracking algorithms</li>
                                    <li>DFS implementation</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">In recursive functions, each call generates a new frame pushed onto the stack until reaching the base condition. Stack's LIFO behavior ensures that each function resumes precisely where it left off.</p>
                        
                        <p class="ds-description">Monotonic Stack: A specialized stack that maintains elements in either non-increasing or non-decreasing order, optimizing access to required element relationships during traversal.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Queue</div>
                        <p class="ds-description">Linear data structure following the First-In-First-Out (FIFO) principle, where the first element added is the first one to be removed.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>O(1) enqueue and dequeue operations</li>
                                    <li>Sequential access pattern</li>
                                    <li>Ideal for order-sensitive processing</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Task scheduling</li>
                                    <li>BFS implementation</li>
                                    <li>Printer spooling</li>
                                    <li>Process management</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Priority Queue</div>
                        <p class="ds-description">A specialized queue where elements have associated priorities and are dequeued based on their priority rather than insertion order.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Implementation:</strong>
                                <ul class="feature-list">
                                    <li>Heap-based data structure</li>
                                    <li>O(log n) insertion and deletion</li>
                                    <li>O(1) access to highest/lowest priority element</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Dijkstra's algorithm</li>
                                    <li>Event-driven simulation</li>
                                    <li>Task scheduling by priority</li>
                                    <li>Huffman coding</li>
                                </ul>
                            </div>
                        </div>                    </div>
                </div>

                <h3>Linked Lists</h3>
                <div class="highlight">
                    <h4>Linked List Structures</h4>
                    <p>Sequential access data structures with non-contiguous memory allocation:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Linked Lists</div>
                        <p class="ds-description">Linear data structure that stores elements in nodes which are not stored in consecutive memory locations. Each node contains its data and a reference to the next node in the sequence, allowing for dynamic memory allocation.</p>
                        
                        <!-- Add LinkedListCycle image for the Linked Lists section -->
                        <div class="image-container">
                            <img src="Public/LinkedListCycle.png" alt="Linked List Cycle Detection" class="algorithm-image">
                            <p class="image-caption">Floyd's Cycle Detection Algorithm: Fast and slow pointers to detect cycles in linked lists</p>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>O(1) time for insertion at the beginning</li>
                                    <li>O(n) time for accessing elements by index</li>
                                    <li>Dynamic size without reallocation</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Algorithms:</strong>
                                <ul class="feature-list">
                                    <li>Fast and Slow Pointers (Floyd's Cycle Detection)</li>
                                    <li>Dummy Node Technique</li>
                                    <li>Reversal algorithms</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Implementation of stacks and queues</li>
                                    <li>Circular buffers</li>
                                    <li>Hash tables (chaining)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Doubly Linked Lists</div>
                        <p class="ds-description">An extension of linked lists where each node contains references to both the next and previous nodes, enabling bidirectional traversal.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>O(1) insertion and deletion at both ends</li>
                                    <li>Bidirectional traversal capability</li>
                                    <li>Higher memory overhead than singly linked lists</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Navigation systems (forward/backward)</li>
                                    <li>LRU cache implementation</li>
                                    <li>Text editors for undo/redo functionality</li>
                                    <li>Browser history implementation</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>                <h3>Hash-Based Structures</h3>
                <div class="highlight">
                    <h4>Fundamentals of Hashing</h4>
                    <p>Hashing transforms input data of arbitrary size into fixed-size values, enabling efficient storage and retrieval:</p>

                    <div class="data-structure-card">
                        <div class="ds-title">Hash Functions</div>
                        <p class="ds-description">Mathematical algorithms that map data of arbitrary size to fixed-size values, ideally distributing keys uniformly across the hash table to minimize collisions.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Properties of Good Hash Functions:</strong>
                                <ul class="feature-list">
                                    <li><strong>Deterministic:</strong> Same input always produces the same output</li>
                                    <li><strong>Uniform Distribution:</strong> Distributes keys evenly across the table</li>
                                    <li><strong>Efficient:</strong> Computes quickly without excessive CPU usage</li>
                                    <li><strong>Avalanche Effect:</strong> Small changes in input cause significant output changes</li>
                                    <li><strong>Low Collision Rate:</strong> Minimizes different keys mapping to the same hash</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Hash Functions:</strong>
                                <ul class="feature-list">
                                    <li><strong>Division Method:</strong> h(k) = k mod m (where m is table size)</li>
                                    <li><strong>Multiplication Method:</strong> h(k) = ‚åäm(kA mod 1)‚åã where A is a constant</li>
                                    <li><strong>Universal Hashing:</strong> Selects functions randomly from a family</li>
                                    <li><strong>Cryptographic:</strong> MD5, SHA-1, SHA-256 (for security applications)</li>
                                    <li><strong>Non-cryptographic:</strong> MurmurHash, xxHash (for high performance)</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">Hash functions convert variable-length inputs into fixed-length outputs that can be used as indices in a hash table. A key challenge in hash function design is balancing speed with collision resistance.</p>
                    </div>

                    <div class="data-structure-card">
                        <div class="ds-title">Collision Handling</div>
                        <p class="ds-description">Techniques to resolve situations when multiple keys hash to the same bucket location, essential for maintaining hash table performance.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Chaining (Separate Chaining):</strong>
                                <ul class="feature-list">
                                    <li>Each bucket contains a linked list or dynamic array of elements</li>
                                    <li>All colliding elements are stored in the same bucket's list</li>
                                    <li>No limit on load factor, but performance degrades as chains grow</li>
                                    <li>Lookup, insert, and delete are O(1 + Œ±) where Œ± is the load factor</li>
                                    <li>Memory overhead for pointers or references</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Open Addressing:</strong>
                                <ul class="feature-list">
                                    <li><strong>Linear Probing:</strong> Check next slot sequentially until empty slot found</li>
                                    <li><strong>Quadratic Probing:</strong> Check positions using quadratic function (h + i¬≤, h + i¬≤ + i, etc.)</li>
                                    <li><strong>Double Hashing:</strong> Use second hash function to determine probe step size</li>
                                    <li>Better cache locality than chaining</li>
                                    <li>Sensitive to load factor (performance degrades above 0.7)</li>
                                    <li>Requires tombstone markers for deleted items</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Robin Hood Hashing:</strong>
                                <ul class="feature-list">
                                    <li>Variant of open addressing that minimizes probe sequence length variance</li>
                                    <li>During insertion, a key may displace another if it has traveled "further from home"</li>
                                    <li>Reduces worst-case lookup times</li>
                                    <li>Maintains more uniform distribution</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Cuckoo Hashing:</strong>
                                <ul class="feature-list">
                                    <li>Uses multiple hash functions and tables</li>
                                    <li>Each key has multiple possible positions</li>
                                    <li>When collision occurs, existing key is kicked out and relocated</li>
                                    <li>Guarantees O(1) worst-case lookups</li>
                                    <li>May require occasional rehashing if insertion cycles detected</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">The choice of collision resolution strategy significantly affects performance characteristics, memory usage, and implementation complexity of hash tables. While chaining is often simpler to implement, open addressing techniques can offer better performance with careful tuning.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Load Factor and Rehashing</div>
                        <p class="ds-description">Critical concepts in hash table implementation that impact performance and memory efficiency as the table fills up.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Load Factor (Œ±):</strong>
                                <ul class="feature-list">
                                    <li>Ratio of filled slots to total slots: Œ± = n/m</li>
                                    <li>Higher load factors save memory but increase collision probability</li>
                                    <li>Lower load factors reduce collisions but waste space</li>
                                    <li>Typical target ranges: 0.5-0.75 for open addressing, 0.75-1.0 for chaining</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Rehashing Process:</strong>
                                <ul class="feature-list">
                                    <li>Create new table with larger capacity (typically 2√ó current size)</li>
                                    <li>Recompute hash for each existing element with new table size</li>
                                    <li>Insert each element into its new position</li>
                                    <li>Replace old table with new table</li>
                                    <li>Amortized cost keeps operations at O(1) average time</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Performance Impacts:</strong>
                                <ul class="feature-list">
                                    <li>Occasional large pauses during rehashing operations</li>
                                    <li>Incremental rehashing can spread cost over multiple operations</li>
                                    <li>Static hash tables (fixed size) avoid rehashing but risk performance degradation</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <h4>HashMaps and Dictionaries</h4>
                    <p>Dynamic data structures that store and manage key-value pairs using hashing techniques:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">HashMaps</div>
                        <p class="ds-description">Each key is processed using a hash function to generate a unique memory address for storing the corresponding value, enabling efficient data retrieval. The internal implementation typically involves an array of buckets with collision resolution strategies.</p>
                        
                        <!-- Add TwoSums image for the hashmap section -->
                        <div class="image-container">
                            <img src="Public/TwoSums.png" alt="Two Sum Algorithm using Hashmaps" class="algorithm-image">
                            <p class="image-caption">Two Sum Problem: Using a HashMap to find pairs that sum to target in O(n) time</p>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>O(1) average time complexity for lookups, insertions, and deletions</li>
                                    <li>O(n) worst-case when many collisions occur</li>
                                    <li>Dynamic size with automatic rehashing when load factor threshold exceeded</li>
                                    <li>Not thread-safe without synchronization</li>
                                    <li>Keys must be immutable or hash code must remain consistent</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Implementation Variations:</strong>
                                <ul class="feature-list">
                                    <li><strong>HashMap:</strong> General-purpose key-value mapping</li>
                                    <li><strong>LinkedHashMap:</strong> Preserves insertion order using doubly-linked list</li>
                                    <li><strong>WeakHashMap:</strong> Uses weak references allowing entries to be garbage collected</li>
                                    <li><strong>IdentityHashMap:</strong> Uses reference equality (==) instead of object equality (equals)</li>
                                    <li><strong>ConcurrentHashMap:</strong> Thread-safe with lock striping for concurrent access</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Techniques:</strong>
                                <ul class="feature-list">
                                    <li>Frequency counting and tracking</li>
                                    <li>Caching and memoization</li>
                                    <li>Two-sum type problems</li>
                                    <li>Grouping and deduplication</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Use Cases:</strong>
                                <ul class="feature-list">
                                    <li>Counting element frequencies</li>
                                    <li>Bi-directional mapping</li>
                                    <li>Caching computed results</li>
                                    <li>Dictionary implementations</li>
                                    <li>Symbol tables in interpreters and compilers</li>
                                    <li>Database indexing and query optimization</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">HashSet</div>
                        <p class="ds-description">A collection that contains no duplicate elements, implementing mathematical set operations with hash table performance. Typically implemented as a wrapper around HashMap with dummy values or as a specialized structure.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>Unique elements only</li>
                                    <li>No key-value pairs, just values (keys with dummy values internally)</li>
                                    <li>O(1) average case operations</li>
                                    <li>No guaranteed element ordering unless using LinkedHashSet</li>
                                    <li>Not synchronized by default</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Implementations:</strong>
                                <ul class="feature-list">
                                    <li><strong>HashSet:</strong> Standard implementation using HashMap</li>
                                    <li><strong>LinkedHashSet:</strong> Maintains insertion order</li>
                                    <li><strong>ConcurrentHashSet:</strong> Thread-safe implementation</li>
                                    <li><strong>EnumSet:</strong> Specialized for enum values</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Duplicate removal</li>
                                    <li>Set operations (union, intersection, difference)</li>
                                    <li>Quick membership testing</li>
                                    <li>De-duplication problems</li>
                                    <li>Tracking visited states in graph algorithms</li>
                                    <li>Implementing sparse bitsets</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Specialized Hash Structures</div>
                        <p class="ds-description">Hash-based data structures optimized for specific use cases that extend beyond standard HashMaps and HashSets.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Bloom Filter:</strong>
                                <ul class="feature-list">
                                    <li>Probabilistic data structure for membership testing</li>
                                    <li>Uses multiple hash functions and a bit array</li>
                                    <li>Can have false positives but never false negatives</li>
                                    <li>Extremely space-efficient</li>
                                    <li>Used for caching, spell checking, network routing</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Count-Min Sketch:</strong>
                                <ul class="feature-list">
                                    <li>Probabilistic data structure for frequency estimation</li>
                                    <li>Uses multiple hash functions and a 2D counter array</li>
                                    <li>Provides approximate counts with bounded error</li>
                                    <li>Space-efficient for tracking stream data</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Consistent Hashing:</strong>
                                <ul class="feature-list">
                                    <li>Distributes keys across multiple servers</li>
                                    <li>Minimizes key redistribution when servers added/removed</li>
                                    <li>Critical for distributed caching and databases</li>
                                    <li>Used in systems like Memcached, Cassandra, DynamoDB</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Perfect Hashing:</strong>
                                <ul class="feature-list">
                                    <li>Guarantees no collisions with a static key set</li>
                                    <li>Often uses two-level hash structure</li>
                                    <li>O(1) worst-case lookup time</li>
                                    <li>Useful for compiler symbol tables and static dictionaries</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Tree Structures</h3>
                <div class="highlight">
                    <h4>Binary Trees</h4>
                    <p>Hierarchical data structures with a root node and at most two children per node:</p>
                      <div class="data-structure-card">
                        <div class="ds-title">Binary Search Tree</div>
                        <p class="ds-description">A binary tree where the left subtree of each node contains only nodes with keys less than the node's key, and the right subtree contains only nodes with keys greater than the node's key.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Ordered key structure follows binary search property</li>
                                    <li>O(log n) operations when balanced, but can degrade to O(n) in worst case</li>
                                    <li>In-order traversal gives sorted sequence</li>
                                    <li>Simpler implementation than balanced alternatives</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Search:</strong> O(h) where h is height</li>
                                    <li><strong>Insert:</strong> O(h), place new node as leaf</li>
                                    <li><strong>Delete:</strong> O(h), with successor replacement</li>
                                    <li><strong>Traversal:</strong> In-order, Pre-order, Post-order</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Implementing associative arrays</li>
                                    <li>Database indexing</li>
                                    <li>Priority queues</li>
                                    <li>Symbol tables in compilers</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">The main weakness of basic BSTs is their tendency to become unbalanced with certain insertion patterns, leading to worst-case O(n) operation times. This issue is addressed by self-balancing variants like AVL and Red-Black trees.</p>
                    </div>
                      <div class="data-structure-card">
                        <div class="ds-title">AVL Trees</div>
                        <p class="ds-description">Self-balancing binary search tree where the heights of the two child subtrees of any node differ by at most one. Named after inventors Adelson-Velsky and Landis, AVL trees were the first dynamically balanced trees to be described.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Strictly balanced with balance factor ‚àà {-1, 0, 1}</li>
                                    <li>Guaranteed O(log n) operations</li>
                                    <li>More rigidly balanced than Red-Black trees</li>
                                    <li>Balance factor = height(left) - height(right)</li>
                                    <li>Maximum height is 1.44 √ó log‚ÇÇ(n+2) - 0.328</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Balancing Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Left Rotation:</strong> For right-heavy subtrees</li>
                                    <li><strong>Right Rotation:</strong> For left-heavy subtrees</li>
                                    <li><strong>Left-Right Rotation:</strong> For left child that's right-heavy</li>
                                    <li><strong>Right-Left Rotation:</strong> For right child that's left-heavy</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Performance Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>Faster lookups than Red-Black trees</li>
                                    <li>More expensive insertion/deletion due to potential cascading rotations</li>
                                    <li>Uses more space per node (balance factor storage)</li>
                                    <li>Maintains better height guarantee than Red-Black</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">AVL trees excel in applications where lookup operations are more frequent than insertions and deletions, as they maintain a more rigid balance that optimizes search performance at the cost of more complex update operations.</p>
                    </div>
                      <div class="data-structure-card">
                        <div class="ds-title">Red-Black Trees</div>
                        <p class="ds-description">Self-balancing binary search tree with each node having an extra attribute for color (red or black), used to ensure balance during operations. Red-Black trees provide efficient worst-case guarantees for insertion, deletion, and search operations.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Self-balancing with color properties</li>
                                    <li>Guaranteed O(log n) operations</li>
                                    <li>Used in many language standard libraries (Java TreeMap, C++ std::map)</li>
                                    <li>Less strictly balanced than AVL trees</li>
                                    <li>Maximum height is 2 √ó log‚ÇÇ(n+1)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Red-Black Properties:</strong>
                                <ul class="feature-list">
                                    <li>Every node is either red or black</li>
                                    <li>The root is black</li>
                                    <li>All leaf nodes (NIL) are black</li>
                                    <li>No red node has a red child (No two reds in a row)</li>
                                    <li>Every path from root to leaf has the same number of black nodes (black-height)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Balancing Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Recoloring:</strong> Change node colors to fix violations</li>
                                    <li><strong>Rotation:</strong> Left and right rotations similar to AVL</li>
                                    <li><strong>Fix-up procedures:</strong> Special algorithms for insertion and deletion</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Performance Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>Faster insertions/deletions than AVL trees</li>
                                    <li>Slightly slower lookups than AVL trees</li>
                                    <li>Fewer rotations on average during updates</li>
                                    <li>Better for write-heavy applications</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">Red-Black trees are often preferred in real-world applications due to their more efficient insertion and deletion operations compared to AVL trees, making them ideal for scenarios with frequent updates. The Linux kernel uses a variant called RB trees for memory management.</p>
                    </div>

                    <div class="section-divider"></div>

                    <h4>Advanced Tree Structures</h4>
                    <p>Specialized tree data structures for specific use cases:</p>
                      <div class="data-structure-card">
                        <div class="ds-title">B-Trees</div>
                        <p class="ds-description">Self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and deletions in logarithmic time. B-Trees generalize binary search trees by allowing nodes to have more than two children.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Multiple keys and children per node (order m: up to m-1 keys, m children)</li>
                                    <li>All leaf nodes at same depth (perfect balance)</li>
                                    <li>Optimized for disk-based storage systems</li>
                                    <li>Minimizes disk I/O operations</li>
                                    <li>Height is logarithmic relative to number of elements: O(log_m(n))</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Node Properties:</strong>
                                <ul class="feature-list">
                                    <li>Non-leaf nodes have at least ‚åàm/2‚åâ children (except root)</li>
                                    <li>All nodes contain between ‚åàm/2‚åâ-1 and m-1 keys (except root)</li>
                                    <li>Keys within each node are stored in ascending order</li>
                                    <li>All keys in a subtree are in the correct range relative to the parent keys</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Search:</strong> O(log_m(n)) - traverse from root to leaf</li>
                                    <li><strong>Insert:</strong> O(log_m(n)) - may require node splits and propagation upward</li>
                                    <li><strong>Delete:</strong> O(log_m(n)) - may require redistribution or merging of nodes</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Database indexing (MySQL's InnoDB, PostgreSQL)</li>
                                    <li>File systems (NTFS, HFS+, ext4)</li>
                                    <li>Search engines (inverted indices)</li>
                                    <li>Key-value stores (Berkeley DB)</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">B-Trees excel in systems where data is stored on slow storage media like disk drives. By storing multiple keys per node, they minimize the number of disk accesses required for operations, drastically improving performance for external storage systems.</p>
                    </div>
                      <div class="data-structure-card">
                        <div class="ds-title">Trie (Prefix Tree)</div>
                        <p class="ds-description">A specialized tree structure optimized for string operations, where each node represents a single character and paths from root to nodes form strings. The name "trie" comes from the word retrieval, highlighting its primary use case.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Character-based tree with shared prefixes</li>
                                    <li>O(m) operations, where m = string length (independent of dataset size)</li>
                                    <li>Each node can have up to alphabet-size children (e.g., 26 for lowercase English)</li>
                                    <li>Common prefixes are represented by shared paths</li>
                                    <li>Terminal nodes or flags indicate complete words</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Insert:</strong> O(m) - follow/create path for each character</li>
                                    <li><strong>Search:</strong> O(m) - traverse path for the string</li>
                                    <li><strong>Delete:</strong> O(m) - remove terminal flag or prune path</li>
                                    <li><strong>Prefix matching:</strong> O(p) where p = prefix length</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Autocomplete and predictive text systems</li>
                                    <li>Spell checkers and dictionary implementations</li>
                                    <li>IP routing tables (CIDR, longest prefix matching)</li>
                                    <li>Word games (like Boggle, Scrabble solvers)</li>
                                    <li>Natural language processing</li>
                                    <li>Genome sequence analysis</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">Tries are extremely efficient for string-specific operations like prefix matching and autocomplete functionality. Their primary advantage is that look-up time is independent of the number of strings stored. However, they can consume significant memory in naive implementations, which has led to compact variants like compressed tries and suffix trees.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">2-3 Trees</div>
                        <p class="ds-description">A self-balancing search tree where internal nodes have either 2 children (and 1 key) or 3 children (and 2 keys). All leaves appear at the same level, ensuring perfect balance.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Perfectly balanced tree with guaranteed O(log n) operations</li>
                                    <li>Every internal node has either 2 or 3 children</li>
                                    <li>All leaves are at the same depth</li>
                                    <li>Conceptual foundation for Red-Black trees</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Node Types:</strong>
                                <ul class="feature-list">
                                    <li><strong>2-node:</strong> Contains 1 key, has 2 children</li>
                                    <li><strong>3-node:</strong> Contains 2 keys, has 3 children</li>
                                    <li>Keys are ordered: smaller key on left, larger on right</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Search:</strong> Similar to BST but with multiple keys per node</li>
                                    <li><strong>Insert:</strong> Split 4-nodes (temporary state during insertion) upward</li>
                                    <li><strong>Delete:</strong> Borrow or merge nodes to maintain tree properties</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Perfect balance without complex rotation procedures</li>
                                    <li>Conceptually simpler than Red-Black trees</li>
                                    <li>Foundation for understanding more complex B-trees</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">2-3 Trees provide an elegant theoretical foundation for balanced trees. While not commonly implemented directly due to the overhead of different node types, their principles directly translate to Red-Black trees, which are effectively a binary tree encoding of 2-3 trees (where red links represent 3-nodes).</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">B+ Trees</div>
                        <p class="ds-description">A variant of B-Tree optimized for storage systems, where all records are stored at the leaf level and leaves are linked for efficient sequential access.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>All data records stored only at leaf nodes</li>
                                    <li>Internal nodes store only keys for navigation</li>
                                    <li>Leaf nodes linked together in sequential order</li>
                                    <li>Higher fanout than regular B-Trees</li>
                                    <li>Better suited for range queries and sequential access</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages over B-Trees:</strong>
                                <ul class="feature-list">
                                    <li>Faster sequential access via leaf node links</li>
                                    <li>More efficient disk space usage</li>
                                    <li>Better query performance for range operations</li>
                                    <li>More keys per node in internal nodes (higher fanout)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Database management systems (most RDBMS indexes)</li>
                                    <li>File systems (NTFS, XFS, JFS)</li>
                                    <li>Indexing in NoSQL systems</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">B+ Trees are the most widely used data structure in database index implementations. By storing data only at leaf level and linking the leaves, they optimize both random access and sequential scanning operations, crucial for database performance. Most modern relational databases use B+ Trees for their primary index structures.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Splay Trees</div>
                        <p class="ds-description">A self-adjusting binary search tree that automatically moves frequently accessed elements closer to the root to improve future access times.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Self-adjusting structure based on access patterns</li>
                                    <li>Recently accessed items moved to root via "splaying"</li>
                                    <li>No explicit balancing information stored</li>
                                    <li>Amortized O(log n) performance</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Splaying Operations:</strong>
                                <ul class="feature-list">
                                    <li><strong>Zig:</strong> Single rotation when parent is root</li>
                                    <li><strong>Zig-Zig:</strong> Double rotation when node and parent are both left/right children</li>
                                    <li><strong>Zig-Zag:</strong> Double rotation when node and parent are opposite children</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Automatically adapts to access patterns</li>
                                    <li>Simple implementation (no balance factors)</li>
                                    <li>Good performance for localized access patterns</li>
                                    <li>Works well as a cache</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Caching systems</li>
                                    <li>Memory management</li>
                                    <li>Network routing tables</li>
                                    <li>Implementing other data structures (e.g., Union-Find)</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">Splay trees excel in applications with non-uniform access patterns, effectively serving as both a search tree and a self-organizing cache. While individual operations might occasionally take O(n) time, the amortized cost remains O(log n), with frequently accessed elements requiring even less time to locate.</p>
                    </div>
                </div>

                <h3>Graph Representations</h3>
                <div class="highlight">
                    <h4>Graph Data Structures</h4>
                    <p>Different ways to represent graph relationships in memory:</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Adjacency Matrix</div>
                        <p class="ds-description">A 2D array where matrix[i][j] represents an edge from vertex i to vertex j, providing constant-time edge lookup.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>O(1) edge lookup</li>
                                    <li>O(V¬≤) space complexity</li>
                                    <li>Better for dense graphs</li>
                                    <li>Memory inefficient for sparse graphs</li>
                                    <li>Adding/removing vertices is O(V¬≤) (requires resizing the matrix)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Simple implementation</li>
                                    <li>Quick edge modifications</li>
                                    <li>Suitable for small graphs</li>
                                    <li>Efficient for dense graphs where E ‚âà V¬≤</li>
                                    <li>Simplifies algorithms like Floyd-Warshall</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Disadvantages:</strong>
                                <ul class="feature-list">
                                    <li>Wasteful for sparse graphs</li>
                                    <li>Less efficient graph traversal (must check every vertex)</li>
                                    <li>Parallel edges require additional data structures</li>
                                    <li>May not fit in memory for large graphs</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="code-example">
                            <pre><code class="language-javascript">
// Adjacency Matrix Implementation (JavaScript)
class Graph {
    constructor(vertices) {
        this.vertices = vertices;
        this.matrix = [];
        
        // Initialize matrix with zeros
        for (let i = 0; i < vertices; i++) {
            this.matrix.push(new Array(vertices).fill(0));
        }
    }
    
    // Add edge from vertex v to vertex w with given weight
    addEdge(v, w, weight = 1) {
        if (v >= 0 && v < this.vertices && w >= 0 && w < this.vertices) {
            this.matrix[v][w] = weight;
            // For undirected graph, add both directions
            // this.matrix[w][v] = weight;
        }
    }
    
    // Check if edge exists from v to w
    hasEdge(v, w) {
        if (v >= 0 && v < this.vertices && w >= 0 && w < this.vertices) {
            return this.matrix[v][w] !== 0;
        }
        return false;
    }
    
    // Get all adjacent vertices of vertex v
    getAdjacentVertices(v) {
        const adjacent = [];
        if (v >= 0 && v < this.vertices) {
            for (let i = 0; i < this.vertices; i++) {
                if (this.matrix[v][i] !== 0) {
                    adjacent.push(i);
                }
            }
        }
        return adjacent;
    }
}
</code></pre>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Adjacency List</div>
                        <p class="ds-description">A collection of lists or arrays where each vertex maintains a list of its adjacent vertices, optimizing space for sparse graphs.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>O(degree(v)) edge lookup (average case)</li>
                                    <li>O(V + E) space complexity</li>
                                    <li>Better for sparse graphs</li>
                                    <li>Efficient traversal of adjacent vertices</li>
                                    <li>Dynamic vertex addition with O(1) complexity</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Space-efficient for sparse graphs</li>
                                    <li>Better performance for most graph algorithms</li>
                                    <li>Easy to represent parallel edges</li>
                                    <li>Efficient for traversal algorithms (BFS, DFS)</li>
                                    <li>Lower memory overhead for real-world networks</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Disadvantages:</strong>
                                <ul class="feature-list">
                                    <li>Slower edge existence check than adjacency matrix</li>
                                    <li>More complex implementation</li>
                                    <li>Edge removal requires searching through lists</li>
                                    <li>No random access to edges</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Social networks</li>
                                    <li>Road networks and navigation</li>
                                    <li>Dependency graphs</li>
                                    <li>Web page link structures</li>
                                    <li>Most real-world network representations</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="code-example">
                            <pre><code class="language-python">
# Adjacency List Implementation (Python)
class Graph:
    def __init__(self):
        self.graph = {}
    
    # Add vertex to the graph
    def add_vertex(self, vertex):
        if vertex not in self.graph:
            self.graph[vertex] = []
    
    # Add edge between vertices (undirected graph)
    def add_edge(self, vertex1, vertex2, weight=1):
        # Ensure both vertices exist
        if vertex1 not in self.graph:
            self.add_vertex(vertex1)
        if vertex2 not in self.graph:
            self.add_vertex(vertex2)
            
        # For weighted graph, store (vertex, weight) tuples
        self.graph[vertex1].append((vertex2, weight))
        # For undirected graph, add both directions
        self.graph[vertex2].append((vertex1, weight))
    
    # Get all adjacent vertices of a vertex
    def get_neighbors(self, vertex):
        if vertex in self.graph:
            return [neighbor for neighbor, _ in self.graph[vertex]]
        return []
    
    # Perform BFS traversal starting from vertex
    def bfs(self, start_vertex):
        if start_vertex not in self.graph:
            return []
            
        visited = set()
        queue = [start_vertex]
        visited.add(start_vertex)
        result = []
        
        while queue:
            current = queue.pop(0)
            result.append(current)
            
            for neighbor, _ in self.graph[current]:
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)
                    
        return result
</code></pre>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Edge List</div>
                        <p class="ds-description">A simple collection of all edges in the graph, often used when the primary operations involve iterating over all edges.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>O(E) edge lookup (linear search through edges)</li>
                                    <li>O(E) space complexity</li>
                                    <li>Simple to implement</li>
                                    <li>Efficient for algorithms that process all edges sequentially</li>
                                    <li>Most compact representation for very sparse graphs</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Memory efficient (stores only what's necessary)</li>
                                    <li>Simple serialization/deserialization</li>
                                    <li>Easy to add or remove edges</li>
                                    <li>Ideal for edge-centric algorithms</li>
                                    <li>Edge properties are easily associated with edges</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Disadvantages:</strong>
                                <ul class="feature-list">
                                    <li>Slow to check if two vertices are connected</li>
                                    <li>Inefficient for finding neighbors of a vertex</li>
                                    <li>Not suitable for vertex-centric traversals</li>
                                    <li>Requires linear search for most operations</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Best Used For:</strong>
                                <ul class="feature-list">
                                    <li>Algorithms that process all edges (MST, Kruskal's)</li>
                                    <li>When memory usage is critical</li>
                                    <li>When edge iteration is the primary operation</li>
                                    <li>Graphs with very few edges relative to vertices</li>
                                    <li>Temporary graph representations</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="code-example">
                            <pre><code class="language-java">
// Edge List Implementation (Java)
import java.util.*;

class Edge {
    int source;
    int destination;
    int weight;
    
    public Edge(int source, int destination, int weight) {
        this.source = source;
        this.destination = destination;
        this.weight = weight;
    }
}

class Graph {
    private int vertices;
    private List<Edge> edges;
    
    public Graph(int vertices) {
        this.vertices = vertices;
        this.edges = new ArrayList<>();
    }
    
    public void addEdge(int source, int destination, int weight) {
        Edge edge = new Edge(source, destination, weight);
        edges.add(edge);
        
        // For undirected graph, add edge in both directions
        // edges.add(new Edge(destination, source, weight));
    }
    
    // Find all edges connected to a vertex (inefficient operation)
    public List<Edge> getEdgesFromVertex(int vertex) {
        List<Edge> result = new ArrayList<>();
        for (Edge edge : edges) {
            if (edge.source == vertex) {
                result.add(edge);
            }
        }
        return result;
    }
    
    // Ideal for MST algorithms like Kruskal's
    public void sortEdgesByWeight() {
        Collections.sort(edges, Comparator.comparingInt(e -> e.weight));
    }
    
    public List<Edge> getAllEdges() {
        return edges;
    }
}
</code></pre>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Incidence Matrix</div>
                        <p class="ds-description">A 2D matrix where rows represent vertices and columns represent edges. Each entry indicates if the vertex is incident to the edge.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Characteristics:</strong>
                                <ul class="feature-list">
                                    <li>O(1) to check if a vertex is incident to an edge</li>
                                    <li>O(V √ó E) space complexity</li>
                                    <li>For directed graphs: +1 for source, -1 for destination, 0 otherwise</li>
                                    <li>For undirected graphs: 1 for incident vertices, 0 otherwise</li>
                                    <li>Allows easy representation of hyper-edges (edges connecting >2 vertices)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Advantages:</strong>
                                <ul class="feature-list">
                                    <li>Easy to find all edges incident to a vertex</li>
                                    <li>Natural representation for edge-focused operations</li>
                                    <li>Can handle parallel edges and self-loops naturally</li>
                                    <li>Suitable for hypergraphs</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Disadvantages:</strong>
                                <ul class="feature-list">
                                    <li>Very space-inefficient</li>
                                    <li>Not commonly used for standard graph algorithms</li>
                                    <li>Slow for finding adjacent vertices</li>
                                    <li>Expensive to modify (add/remove vertices or edges)</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description">Incidence matrices are less common than adjacency matrices or adjacency lists but provide unique advantages for certain theoretical applications and problems involving hypergraphs.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Implicit Graph Representation</div>
                        <p class="ds-description">A representation where the graph structure is defined by functions rather than explicitly stored data structures, useful for graphs too large to fit in memory or for dynamically generated graphs.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Graph structure is computed on demand rather than stored</li>
                                    <li>Neighbors are determined by rules or functions</li>
                                    <li>Can represent infinite graphs</li>
                                    <li>Memory usage independent of graph size</li>
                                    <li>Common in computational geometry, game AI, and procedural generation</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Grid-based pathfinding (game maps)</li>
                                    <li>State space search problems</li>
                                    <li>Infinite graphs (mathematical models)</li>
                                    <li>Procedurally generated worlds</li>
                                    <li>Constraint satisfaction problems</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="code-example">
                            <pre><code class="language-javascript">
// Implicit Graph for Grid-Based Pathfinding (JavaScript)
class GridGraph {
    constructor(width, height) {
        this.width = width;
        this.height = height;
        // We can optionally store obstacle information
        this.obstacles = new Set();
    }
    
    // Helper to convert 2D coordinates to a single identifier
    toId(x, y) {
        return y * this.width + x;
    }
    
    // Helper to convert ID back to coordinates
    toCoords(id) {
        return {
            x: id % this.width,
            y: Math.floor(id / this.width)
        };
    }
    
    // Add obstacle at coordinates
    addObstacle(x, y) {
        this.obstacles.add(this.toId(x, y));
    }
    
    // Check if position is valid and walkable
    isValid(x, y) {
        return x >= 0 && x < this.width && 
               y >= 0 && y < this.height && 
               !this.obstacles.has(this.toId(x, y));
    }
    
    // Get neighbors of a cell - this is our implicit edge definition
    getNeighbors(x, y) {
        const directions = [
            {x: 0, y: -1},  // Up
            {x: 1, y: 0},   // Right
            {x: 0, y: 1},   // Down
            {x: -1, y: 0}   // Left
            // Add diagonals if needed:
            // {x: 1, y: -1}, {x: 1, y: 1}, {x: -1, y: 1}, {x: -1, y: -1}
        ];
        
        return directions
            .map(dir => ({x: x + dir.x, y: y + dir.y}))
            .filter(pos => this.isValid(pos.x, pos.y));
    }
    
    // Recursive implementation of BFS using a generator function
    *recursiveBFS(startX, startY) {
        const visited = new Set();
        const queue = [{x: startX, y: startY}];
        visited.add(this.toId(startX, startY));
        
        const processNextLevel = () => {
            if (queue.length === 0) return;
            
            const levelSize = queue.length;
            for (let i = 0; i < levelSize; i++) {
                const current = queue.shift();
                
                // Yield the current position
                yield current;
                
                // Get and process neighbors
                const neighbors = this.getNeighbors(current.x, current.y);
                for (const neighbor of neighbors) {
                    const id = this.toId(neighbor.x, neighbor.y);
                    if (!visited.has(id)) {
                        visited.add(id);
                        queue.push(neighbor);
                    }
                }
            }
            
            // Process the next level recursively
            yield* processNextLevel();
        };
        
        // Start the recursive BFS
        yield* processNextLevel();
    }
}

// Example usage
const graph = {
    A: ['B', 'C'],
    B: ['A', 'D', 'E'],
    C: ['A', 'F'],
    D: ['B'],
    E: ['B', 'F'],
    F: ['C', 'E']
};

console.log("Iterative BFS:", bfs(graph, 'A'));
console.log("Recursive BFS:", recursiveBFS(graph, 'A'));
// Both produce the same result: ['A', 'B', 'C', 'D', 'E', 'F']
</code></pre>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Comparison and Selection Guide</div>
                        <p class="ds-description">Choosing the right graph representation depends on several factors including graph density, memory constraints, and the operations you need to perform frequently.</p>
                        
                        <table class="comparison-table">
                            <thead>
                                <tr>
                                    <th>Operation</th>
                                    <th>Adjacency Matrix</th>
                                    <th>Adjacency List</th>
                                    <th>Edge List</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Memory Usage</td>
                                    <td>O(V¬≤)</td>
                                    <td>O(V + E)</td>
                                    <td>O(E)</td>
                                </tr>
                                <tr>
                                    <td>Edge Existence Check</td>
                                    <td>O(1)</td>
                                    <td>O(degree)</td>
                                    <td>O(E)</td>
                                </tr>
                                <tr>
                                    <td>Find All Edges</td>
                                    <td>O(V¬≤)</td>
                                    <td>O(V + E)</td>
                                    <td>O(1)</td>
                                </tr>
                                <tr>
                                    <td>Find All Neighbors</td>
                                    <td>O(V)</td>
                                    <td>O(1) + O(degree)</td>
                                    <td>O(E)</td>
                                </tr>
                                <tr>
                                    <td>Add Edge</td>
                                    <td>O(1)</td>
                                    <td>O(1)</td>
                                    <td>O(1)</td>
                                </tr>
                                <tr>
                                    <td>Add Vertex</td>
                                    <td>O(V¬≤) (resizing)</td>
                                    <td>O(1)</td>
                                    <td>O(1)</td>
                                </tr>
                                <tr>
                                    <td>Remove Edge</td>
                                    <td>O(1)</td>
                                    <td>O(degree)</td>
                                    <td>O(E)</td>
                                </tr>
                                <tr>
                                    <td>Graph Traversal (BFS/DFS)</td>
                                    <td>O(V¬≤)</td>
                                    <td>O(V + E)</td>
                                    <td>O(V*E)</td>
                                </tr>
                            </tbody>
                        </table>
                        
                        <div class="feature-group">
                            <div>
                                <strong>When to Choose Adjacency Matrix:</strong>
                                <ul class="feature-list">
                                    <li>Dense graphs (E ‚âà V¬≤)</li>
                                    <li>Small graphs (< 1000 vertices)</li>
                                    <li>Need fast edge lookups and modifications</li>
                                    <li>Implementing algorithms like Floyd-Warshall</li>
                                    <li>When graph is relatively static (few vertex additions)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>When to Choose Adjacency List:</strong>
                                <ul class="feature-list">
                                    <li>Sparse graphs (E << V¬≤)</li>
                                    <li>Most general-purpose applications</li>
                                    <li>When traversing adjacent vertices frequently</li>
                                    <li>Memory-constrained environments</li>
                                    <li>Dynamic graphs with changing vertices</li>
                                    <li>Implementing most graph algorithms (DFS, BFS, Dijkstra's)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>When to Choose Edge List```html
                                <strong>When to Choose Edge List:</strong>
                                <ul class="feature-list">
                                    <li>Very sparse graphs</li>
                                    <li>Implementing algorithms that process all edges (MST)</li>
                                    <li>When memory usage is critical</li>
                                    <li>When edge iteration is the primary operation</li>
                                    <li>Graphs with very few edges relative to vertices</li>
                                    <li>Temporary graph representations</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Graph Traversal Algorithms</h3>
                <div class="highlight">
                    <div class="data-structure-card">
                        <div class="ds-title">Breadth-First Search (BFS)</div>
                        <p class="ds-description">A level-by-level traversal strategy for graphs, trees and matrixes that explores all neighbors of a node before moving to the next level.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Implementation:</strong>
                                <ul class="feature-list">
                                    <li>Uses Queue data structure</li>
                                    <li>Tracks visited nodes to avoid cycles</li>
                                    <li>Time Complexity: O(V + E)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Shortest path in unweighted graphs</li>
                                    <li>Level-order traversal in trees</li>
                                    <li>Finding connected components</li>
                                    <li>Social network connections</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="code-example">
                            <pre><code class="language-javascript">
// Iterative BFS Implementation
function bfs(graph, startVertex) {
    const visited = new Set();
    const queue = [startVertex];
    visited.add(startVertex);
    const result = [];
    
    while (queue.length > 0) {
        const currentVertex = queue.shift();
        result.push(currentVertex);
        
        // Get all adjacent vertices of the current vertex
        const neighbors = graph[currentVertex] || [];
        
        for (const neighbor of neighbors) {
            if (!visited.has(neighbor)) {
                visited.add(neighbor);
                queue.push(neighbor);
            }
        }
    }
    
    return result;
}

// Recursive implementation of BFS using a generator function
function* recursiveBFS(graph, startVertex) {
    const visited = new Set();
    const queue = [startVertex];
    visited.add(startVertex);
    const result = [];
    
    // Helper function to process one level at a time
    function processNextLevel() {
        if (queue.length === 0) {
            return; // Base case: no more vertices to process
        }
        
        const levelSize = queue.length;
        
        // Process all vertices at current level
        for (let i = 0; i < levelSize; i++) {
            const currentVertex = queue.shift();
            result.push(currentVertex);
            
            // Add unvisited neighbors to queue
            const neighbors = graph[currentVertex] || [];
            for (const neighbor of neighbors) {
                if (!visited.has(neighbor)) {
                    visited.add(neighbor);
                    queue.push(neighbor);
                }
            }
        }
        
        // Recursively process the next level
        processNextLevel();
    }
    
    // Start the recursive BFS
    processNextLevel();
    return result;
}

// Example usage
const graph = {
    A: ['B', 'C'],
    B: ['A', 'D', 'E'],
    C: ['A', 'F'],
    D: ['B'],
    E: ['B', 'F'],
    F: ['C', 'E']
};

console.log("Iterative BFS:", bfs(graph, 'A'));
console.log("Recursive BFS:", recursiveBFS(graph, 'A'));
// Both produce the same result: ['A', 'B', 'C', 'D', 'E', 'F']
</code></pre>
                        </div>
                        
                        <p class="ds-description">While recursive BFS is less common than iterative BFS (since BFS naturally fits the queue data structure), the recursive approach can be useful for certain applications where level-by-level processing is important, or when working with frameworks that favor recursive patterns.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Recursive BFS Benefits:</strong>
                                <ul class="feature-list">
                                    <li>Clear separation of level processing</li>
                                    <li>Easier tracking of depth/distance from source</li>
                                    <li>Simplified level-specific operations</li>
                                    <li>Can be implemented with generators for lazy evaluation</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Considerations:</strong>
                                <ul class="feature-list">
                                    <li>Potential stack overflow for very deep graphs</li>
                                    <li>Extra function call overhead</li>
                                    <li>Typically less efficient than iterative version</li>
                                    <li>Memory overhead from call stack</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="data-structure-card">
                        <div class="ds-title">Depth-First Search (DFS)</div>
                        <p class="ds-description">A traversal strategy that explores paths to their maximum depth before backtracking, often implemented using recursion or stack.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Implementation:</strong>
                                <ul class="feature-list">
                                    <li>Uses Stack or Recursion</li>
                                    <li>Maintains visited set for cycle detection</li>
                                    <li>Time Complexity: O(V + E)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Cycle detection in graphs</li>
                                    <li>Maze solving algorithms</li>
                                    <li>Topological sorting</li>
                                    <li>Finding connected components</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Dijkstra's Algorithm</div>
                        <p class="ds-description">Greedy algorithm that finds the shortest path from a single source vertex to all other vertices in a weighted graph with non-negative edges.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Implementation:</strong>
                                <ul class="feature-list">
                                    <li>Uses Priority Queue (Min Heap)</li>
                                    <li>Maintains distance array and visited set</li>
                                    <li>Time Complexity: O((V + E) log V)</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>GPS and navigation systems</li>
                                    <li>Network routing protocols</li>
                                    <li>Finding shortest connection in networks</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">A* Search Algorithm</div>
                        <p class="ds-description">Informed search algorithm that uses heuristics to find the shortest path, combining Dijkstra's algorithm with additional information about goal proximity.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Features:</strong>
                                <ul class="feature-list">
                                    <li>Uses heuristic function h(n) to estimate distance to goal</li>
                                    <li>Evaluation function: f(n) = g(n) + h(n)</li>
                                    <li>More efficient than Dijkstra's with good heuristic</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Applications:</strong>
                                <ul class="feature-list">
                                    <li>Video game pathfinding</li>
                                    <li>Robot navigation</li>
                                    <li>Route planning in maps</li>
                                    <li>Puzzle solving (8-puzzle, 15-puzzle)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="system-design">
                <h2>Modern System Design Principles</h2>

                <h3>Non-Functional Requirements</h3>
                <div class="highlight">
                    <p>Non-functional requirements define the quality attributes of a system that affect how well it performs its functions rather than what specific functions it performs.</p>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Scalability</div>
                        <p class="ds-description">The capability of a system to handle growing amounts of work by adding resources to the system.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Aspects:</strong>
                                <ul class="feature-list">
                                    <li>Vertical Scaling (Scale Up): Adding more power to existing machines</li>
                                    <li>Horizontal Scaling (Scale Out): Adding more machines to your resource pool</li>
                                    <li>Auto-scaling: Dynamically adjusting resources based on demand</li>
                                    <li>Load distribution: Efficiently balancing workload across resources</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Measurement:</strong>
                                <ul class="feature-list">
                                    <li>Requests per second (RPS) under increasing load</li>
                                    <li>Throughput: volume of data/transactions processed</li>
                                    <li>Response time stability at scale</li>
                                    <li>Resource utilization efficiency</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Design Considerations:</strong>
                                <ul class="feature-list">
                                    <li>Stateless design for horizontal scaling</li>
                                    <li>Data partitioning and sharding strategies</li>
                                    <li>Caching hierarchies for read scaling</li>
                                    <li>Asynchronous processing for workload decoupling</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Availability</div>
                        <p class="ds-description">The proportion of time that a system is in a functioning condition, often measured as a percentage of uptime in a given period.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Measurement:</strong>
                                <ul class="feature-list">
                                    <li><strong>99.9% (Three nines)</strong>: 8.76 hours/year downtime</li>
                                    <li><strong>99.99% (Four nines)</strong>: 52.56 minutes/year downtime</li>
                                    <li><strong>99.999% (Five nines)</strong>: 5.26 minutes/year downtime</li>
                                    <li><strong>99.9999% (Six nines)</strong>: 31.5 seconds/year downtime</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Strategies:</strong>
                                <ul class="feature-list">
                                    <li>Redundancy: Multiple instances of critical components</li>
                                    <li>Failover mechanisms: Automatic recovery from component failure</li>
                                    <li>Fault isolation: Containing failures to minimize impact</li>
                                    <li>Geographic distribution: Multiple data centers/regions</li>
                                    <li>Chaos engineering: Systematically testing resilience</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Industry Examples:</strong>
                                <ul class="feature-list">
                                    <li>Netflix Chaos Monkey: Deliberately terminates instances to test resilience</li>
                                    <li>Amazon Route 53: Offers 100% availability SLA using multi-region redundancy</li>
                                    <li>Google Cloud Spanner: Provides 99.999% availability with multi-region deployment</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Reliability</div>
                        <p class="ds-description">The ability of a system to consistently perform its intended function correctly and deliver expected results over time.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Aspects:</strong>
                                <ul class="feature-list">
                                    <li>Mean Time Between Failures (MTBF)</li>
                                    <li>Mean Time To Recovery (MTTR)</li>
                                    <li>Error rates and failure frequency</li>
                                    <li>Data integrity and consistency</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Design Principles:</strong>
                                <ul class="feature-list">
                                    <li>Circuit breakers: Preventing cascading failures</li>
                                    <li>Retry mechanisms with exponential backoff</li>
                                    <li>Bulkheads: Isolating components to contain failures</li>
                                    <li>Timeouts: Avoiding resource exhaustion</li>
                                    <li>Idempotency: Safe operation repetition</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Performance</div>
                        <p class="ds-description">Indicators of how quickly a system responds to inputs and processes data under various conditions.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Metrics:</strong>
                                <ul class="feature-list">
                                    <li><strong>Latency</strong>: Time taken to respond to a request</li>
                                    <li><strong>Throughput</strong>: Number of operations processed per unit of time</li>
                                    <li><strong>Response Time</strong>: Total time from request to complete response</li>
                                    <li><strong>Processing Time</strong>: Time taken to process a transaction</li>
                                    <li><strong>Resource Utilization</strong>: CPU, memory, disk, network usage percentages</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Optimization Techniques:</strong>
                                <ul class="feature-list">
                                    <li>Caching: Storing frequently accessed data in fast access storage</li>
                                    <li>Connection pooling: Reusing expensive database connections</li>
                                    <li>Content Delivery Networks (CDNs): Distributing content geographically closer to users</li>
                                    <li>Data indexing: Optimizing data retrieval operations</li>
                                    <li>Lazy loading: Deferring initialization of resources until needed</li>
                                    <li>Asynchronous processing: Non-blocking operations for better resource utilization</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Security</div>
                        <p class="ds-description">Protection of system components and data from unauthorized access and potential threats.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Security Principles:</strong>
                                <ul class="feature-list">
                                    <li><strong>CIA Triad</strong>: Confidentiality, Integrity, Availability</li>
                                    <li><strong>Defense in Depth</strong>: Multiple layers of security controls</li>
                                    <li><strong>Principle of Least Privilege</strong>: Minimum necessary permissions</li>
                                    <li><strong>Zero Trust</strong>: Never trust, always verify</li>
                                    <li><strong>Secure by Design</strong>: Security built-in, not added on</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Common Security Measures:</strong>
                                <ul class="feature-list">
                                    <li>Authentication and authorization frameworks</li>
                                    <li>Data encryption (in transit and at rest)</li>
                                    <li>API security (rate limiting, input validation)</li>
                                    <li>Regular security audits and penetration testing</li>
                                    <li>Intrusion detection and prevention systems</li>
                                    <li>Compliance with industry standards (GDPR, HIPAA, PCI DSS)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Maintainability</div>
                        <p class="ds-description">The ease with which a system can be modified, enhanced, or debugged to correct faults, improve performance, or adapt to a changed environment.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Key Aspects:</strong>
                                <ul class="feature-list">
                                    <li><strong>Modularity</strong>: Independent, replaceable components</li>
                                    <li><strong>Code quality</strong>: Readability, consistency, conventions</li>
                                    <li><strong>Technical debt management</strong>: Regular refactoring</li>
                                    <li><strong>Documentation</strong>: Clear architecture and API docs</li>
                                    <li><strong>Testability</strong>: Automated testing capabilities</li>
                                </ul>
                            </div>
                            
                            <div>
                                <strong>Best Practices:</strong>
                                <ul class="feature-list">
                                    <li>Continuous Integration/Continuous Deployment (CI/CD)</li>
                                    <li>Infrastructure as Code (IaC)</li>
                                    <li>Observability (logging, monitoring, tracing)</li>
                                    <li>Consistent coding standards and peer reviews</li>
                                    <li>Feature flags for controlled rollouts</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <h3>Key System Design Patterns</h3>
                <div class="highlight">
                    <div class="data-structure-card">
                        <div class="ds-title">Distributed System Patterns</div>
                        <p class="ds-description">Design patterns to address common challenges in building reliable, scalable, and maintainable distributed systems.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Circuit Breaker Pattern</strong>
                                <ul class="feature-list">
                                    <li><strong>Purpose:</strong> Prevent cascading failures by detecting failures and encapsulating logic for preventing a failure from constantly recurring</li>
                                    <li><strong>Implementation:</strong> Three states (Closed, Open, Half-Open) with fallback mechanisms</li>
                                    <li><strong>Popular Libraries:</strong> Resilience4j, Hystrix, Polly</li>
                                    <li><strong>Use Cases:</strong> API calls, remote service invocations, resource-intensive operations</li>
                                </ul>
                                <p><strong>Example:</strong> When a service consistently fails to respond, the circuit breaker opens, immediately rejecting requests without attempting to call the failing service, then gradually allows test requests to check if the system has recovered.</p>
                            </div>
                            
                            <div>
                                <strong>Bulkhead Pattern</strong>
                                <ul class="feature-list">
                                    <li><strong>Purpose:</strong> Isolate failures to prevent them from cascading through the system</li>
                                    <li><strong>Implementation:</strong> Separate thread pools, connection pools, or process boundaries</li>
                                    <li><strong>Variants:</strong> Thread pool bulkhead, semaphore bulkhead, process bulkhead</li>
                                    <li><strong>Use Cases:</strong> Multiple client integrations, resource partitioning, critical vs. non-critical operations</li>
                                </ul>
                                <p><strong>Example:</strong> A system using separate connection pools for critical vs. non-critical database operations ensures that resource exhaustion in one pool doesn't affect the other.</p>
                            </div>
                            
                            <div>
                                <strong>Saga Pattern</strong>
                                <ul class="feature-list">
                                    <li><strong>Purpose:</strong> Manage distributed transactions and maintain data consistency across services</li>
                                    <li><strong>Implementation:</strong> Choreography (event-based) or Orchestration (central coordinator)</li>
                                    <li><strong>Key Components:</strong> Local transactions, compensating transactions</li>
                                    <li><strong>Use Cases:</strong> E-commerce order processing, financial transactions, multi-step business processes</li>
                                </ul>
                                <p><strong>Example:</strong> An order process spanning inventory, payment, and shipping services where each step publishes events that trigger subsequent steps, with compensating transactions to roll back changes if any step fails.</p>
                            </div>
                            
                            <div>
                                <strong>CQRS (Command Query Responsibility Segregation)</strong>
                                <ul class="feature-list">
                                    <li><strong>Purpose:</strong> Separate read and write operations for different optimization strategies</li>
                                    <li><strong>Implementation:</strong> Different models for commands (writes) and queries (reads)</li>
                                    <li><strong>Variants:</strong> Single database, dual database, event sourcing integration</li>
                                    <li><strong>Use Cases:</strong> High-read systems, complex domains, advanced reporting needs</li>
                                </ul>
                                <p><strong>Example:</strong> An e-commerce platform using normalized SQL database for order processing (commands) and denormalized NoSQL database for product catalog browsing (queries).</p>
                            </div>
                            
                            <div>
                                <strong>Event Sourcing</strong>
                                <ul class="feature-list">
                                    <li><strong>Purpose:</strong> Store state changes as a sequence of events rather than just the current state</li>
                                    <li><strong>Implementation:</strong> Append-only event store with projections</li>
                                    <li><strong>Benefits:</strong> Complete audit trail, time-travel debugging, reliable event publishing</li>
                                    <li><strong>Use Cases:</strong> Financial systems, inventory tracking, collaborative applications</li>
                                </ul>
                                <p><strong>Example:</strong> A banking system storing all account transactions as immutable events, rebuilding account balance by replaying events, and enabling historical analysis of all state changes.</p>
                            </div>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Architectural Considerations:</strong>
                                <p>Distributed system patterns often work best when combined strategically. For example, Event Sourcing frequently complements CQRS by providing the event stream for building specialized read models. Similarly, Circuit Breakers and Bulkheads often work together as part of a comprehensive resiliency strategy. The complexity of implementing these patterns has led to the emergence of specialized frameworks and libraries that provide out-of-box implementations with configurable behaviors.</p>
                                <p>When applying these patterns, consider:</p>
                                <ul class="feature-list">
                                    <li><strong>Complexity Cost:</strong> These patterns introduce additional complexity that must be justified by the benefits</li>
                                    <li><strong>Team Expertise:</strong> Ensure the development team understands the patterns and their implications</li>
                                    <li><strong>Monitoring Requirements:</strong> Distributed patterns require sophisticated observability solutions</li>
                                    <li><strong>Eventual Consistency:</strong> Many of these patterns trade immediate consistency for availability and partition tolerance</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Containerization and Orchestration</div>
                        <p class="ds-description">Container technologies provide a standardized way to package and deploy applications, while orchestration platforms manage container lifecycle at scale.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Docker</strong>
                                <ul class="feature-list">
                                    <li><strong>Architecture:</strong> Lightweight containers sharing the host OS kernel</li>
                                    <li><strong>Components:</strong> Docker Engine, Images, Containers, Registry</li>
                                    <li><strong>Key Features:</strong> Isolation, portability, version control, resource efficiency</li>
                                    <li><strong>Use Cases:</strong> Application packaging, development environments, CI/CD pipelines</li>
                                </ul>
                                <p><strong>Strengths:</strong> Simplified application distribution, consistent environments, resource efficiency compared to VMs.</p>
                                <p><strong>Limitations:</strong> Single-host by default, security considerations, persistent data management complexity.</p>
                            </div>
                            
                            <div>
                                <strong>Kubernetes</strong>
                                <ul class="feature-list">
                                    <li><strong>Architecture:</strong> Container orchestration platform with master-node model</li>
                                    <li><strong>Core Objects:</strong> Pods, Services, Deployments, StatefulSets, ConfigMaps</li>
                                    <li><strong>Key Features:</strong> Auto-scaling, self-healing, service discovery, rolling updates</li>
                                    <li><strong>Components:</strong> API Server, Scheduler, Controller Manager, etcd, Kubelet</li>
                                    <li><strong>Use Cases:</strong> Microservices deployment, hybrid cloud systems, large-scale applications</li>
                                </ul>
                                <p><strong>Strengths:</strong> Production-ready orchestration, extensive ecosystem, declarative configuration, high resilience.</p>
                                <p><strong>Limitations:</strong> Steep learning curve, operational complexity, resource overhead for small deployments.</p>
                            </div>
                            
                            <div>
                                <strong>Docker Swarm</strong>
                                <ul class="feature-list">
                                    <li><strong>Architecture:</strong> Native clustering for Docker with manager and worker nodes</li>
                                    <li><strong>Key Features:</strong> Simple setup, Docker CLI integration, service scaling</li>
                                    <li><strong>Use Cases:</strong> Simpler orchestration needs, Docker-centric environments</li>
                                </ul>
                                <p><strong>Strengths:</strong> Lower complexity than Kubernetes, native Docker integration, easier learning curve.</p>
                                <p><strong>Limitations:</strong> Fewer features than Kubernetes, smaller ecosystem, less advanced networking.</p>
                            </div>
                            
                            <div>
                                <strong>Service Mesh (Istio, Linkerd)</strong>
                                <ul class="feature-list">
                                    <li><strong>Architecture:</strong> Network of proxies alongside containers for communication control</li>
                                    <li><strong>Key Features:</strong> Traffic management, security, observability, policy enforcement</li>
                                    <li><strong>Components:</strong> Data plane (proxies), Control plane (management)</li>
                                    <li><strong>Use Cases:</strong> Complex microservices requiring advanced traffic control, security, and monitoring</li>
                                </ul>
                                <p><strong>Strengths:</strong> Service-to-service communication management, encryption, monitoring, traffic shaping.</p>
                                <p><strong>Limitations:</strong> Additional complexity layer, performance overhead, steep learning curve.</p>
                            </div>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Comparison Table</strong>
                                <table class="comparison-table">
                                    <thead>
                                        <tr>
                                            <th>Feature</th>
                                            <th>Kubernetes</th>
                                            <th>Docker Swarm</th>
                                            <th>Amazon ECS</th>
                                            <th>Google Cloud Run</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Complexity</td>
                                            <td>High</td>
                                            <td>Low</td>
                                            <td>Medium</td>
                                            <td>Very Low</td>
                                        </tr>
                                        <tr>
                                            <td>Scaling Capacity</td>
                                            <td>Very High</td>
                                            <td>Medium</td>
                                            <td>High</td>
                                            <td>High</td>
                                        </tr>
                                        <tr>
                                            <td>Auto-Scaling</td>
                                            <td>Advanced</td>
                                            <td>Basic</td>
                                            <td>Yes</td>
                                            <td>Automatic</td>
                                        </tr>
                                        <tr>
                                            <td>GUI Dashboard</td>
                                            <td>Yes</td>
                                            <td>Limited</td>
                                            <td>Yes</td>
                                            <td>Yes</td>
                                        </tr>
                                        <tr>
                                            <td>Deployment Model</td>
                                            <td>Any Cloud/On-Premise</td>
                                            <td>Any Cloud/On-Premise</td>
                                            <td>AWS Only</td>
                                            <td>Google Cloud Only</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                        
                        <p class="ds-description"><strong>Architectural Considerations:</strong> Container orchestration selection depends heavily on system scale, team expertise, and organizational ecosystem. For simpler applications or teams new to containerization, Docker Swarm or managed platforms like ECS may be appropriate starting points. For large-scale, multi-service applications requiring sophisticated deployment strategies and scaling capabilities, Kubernetes has become the de facto standard. In many organizations, a hybrid approach emerges: simpler services on managed platforms and more complex, critical services on Kubernetes. Service meshes add another layer that becomes valuable as microservice count grows beyond dozens of services and communication patterns become more complex.</p>
                    </div>
                    
                    <div class="data-structure-card">
                        <div class="ds-title">Observability and Monitoring</div>
                        <p class="ds-description">Systems for gaining insights into the behavior, performance, and health of distributed applications in production environments.</p>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Three Pillars of Observability</strong>
                                <ul class="feature-list">
                                    <li><strong>Metrics:</strong> Numerical representations of system behavior over time (counters, gauges, histograms)</li>
                                    <li><strong>Logs:</strong> Text records of discrete events that occurred in the system</li>
                                    <li><strong>Traces:</strong> Records of operations across service boundaries with timing and causal relationships</li>
                                </ul>
                                <p>Modern observability solutions combine these three dimensions to provide a comprehensive view of system behavior, enabling effective troubleshooting, performance optimization, and anomaly detection.</p>
                            </div>
                            
                            <div>
                                <strong>Metrics Systems</strong>
                                <ul class="feature-list">
                                    <li><strong>Prometheus:</strong> Open-source time-series database with a powerful query language (PromQL), pull model, and alerting</li>
                                    <li><strong>Grafana:</strong> Visualization platform for metrics with dashboards, alerting, and multi-data-source support</li>
                                    <li><strong>Datadog:</strong> SaaS platform for metrics, logs, and traces with comprehensive integrations and automated correlation</li>
                                    <li><strong>CloudWatch:</strong> AWS native monitoring and observability service with metric collection, dashboards, and alarms</li>
                                </ul>
                                <p><strong>Key Considerations:</strong> Cardinality management, retention policies, aggregation functions, and alerting capabilities</p>
                            </div>
                            
                            <div>
                                <strong>Logging Systems</strong>
                                <ul class="feature-list">
                                    <li><strong>ELK Stack:</strong> Elasticsearch (storage/search), Logstash (processing), Kibana (visualization)</li>
                                    <li><strong>Fluentd/Fluent Bit:</strong> Unified logging layers that collect, transform and ship logs to various backends</li>
                                    <li><strong>Loki:</strong> Highly-efficient, Prometheus-inspired log aggregation system designed for cost and scale</li>
                                    <li><strong>Splunk:</strong> Enterprise platform for searching, monitoring, and analyzing machine-generated data</li>
                                </ul>
                                <p><strong>Key Considerations:</strong> Structured logging formats (JSON), log levels, sampling strategies, retention, and indexing</p>
                            </div>
                            
                            <div>
                                <strong>Tracing Systems</strong>
                                <ul class="feature-list">
                                    <li><strong>Jaeger:</strong> Open-source, distributed tracing system for microservices with OpenTracing support</li>
                                    <li><strong>Zipkin:</strong> Distributed tracing system that helps gather timing data for troubleshooting latency problems</li>
                                    <li><strong>OpenTelemetry:</strong> Vendor-neutral framework for collecting traces, metrics, and logs (CNCF project)</li>
                                    <li><strong>AWS X-Ray:</strong> Tracing system for applications running on AWS with request visualization and filtering</li>
                                </ul>
                                <p><strong>Key Considerations:</strong> Sampling rates, context propagation, instrumentation methods, and visualization</p>
                            </div>
                        </div>
                        
                        <div class="feature-group">
                            <div>
                                <strong>Implementation Best Practices</strong>
                                <ul class="feature-list">
                                    <li><strong>USE Method:</strong> Monitor Utilization, Saturation, and Errors for all resources</li>
                                    <li><strong>RED Method:</strong> Track Rate, Errors, and Duration for all services</li>
                                    <li><strong>SLIs/SLOs:</strong> Define Service Level Indicators and Objectives for monitoring service health</li>
                                    <li><strong>Contextual Correlation:</strong> Ensure metrics, logs, and traces can be correlated via shared identifiers</li>
                                    <li><strong>Cost Management:</strong> Implement sampling, filtering, and retention policies to control data volume</li>
                                    <li><strong>Alerting Hygiene:</strong> Design alerts that minimize noise and clearly indicate actionable issues</li>
                                </ul>
                            </div>
                        </div>
                        
                        <p class="ds-description"><strong>Architectural Considerations:</strong> Effective observability requires a holistic approach integrated throughout the system design process, not added as an afterthought. In modern distributed systems, the challenges of troubleshooting across service boundaries make comprehensive observability essential. While many organizations start with metrics for their simplicity and low overhead, the progressive addition of structured logging and tracing capabilities becomes necessary as system complexity increases. The trend toward unified observability platforms that correlate all three pillars helps teams quickly identify and resolve issues in complex distributed environments.</p>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <footer class="footer">
        <div class="container">
            <p>¬© 2024 Software Engineering Guide</p>
        </div>
    </footer>
</body>
</html>
